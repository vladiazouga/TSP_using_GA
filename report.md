# Overview / Report

*Emmanuel David*

In this assignment, we were asked to create a smart computer program using a genetic algorithm. This program tackles a tricky problem called the traveling salesperson problem. It's so tough because there are just too many possible solutions to check them all one by one.

A genetic algorithm is like a smart computer trick. It works a bit like nature, where a bunch of possible answers are tested over and over. The best ones get mixed together to make even better answers.

For our project, we had to find the shortest path through a bunch of cities, starting and ending in the same city. We took some ideas from Hubbs' way of doing this. He showed us how breaking big tasks into smaller steps can make things much clearer.

We used 25 cities for our project. This number gave a good balance. It made the program run nicely, and each time we use it, we get different results to explore.

Finally, this project was done by Giovanni Smith (design), Vladia Zouga (coding), and myself. Giovanni took care of designing the approach and providing a clear visual representation of the algorithm's progress. Vladia's expertise in coding was invaluable in implementing the algorithm efficiently and ensuring it runs smoothly. Together, our collaboration resulted in a robust and effective solution to the traveling salesperson problem.

## Question Responses

1. After representing cities using a structured list called `citiesList`, the program dynamically calculates distances between them as it runs. This involves finding the difference in x and y coordinates for each pair of cities, ensuring the values are positive, and then calculating the overall distance.
2. The concept of a "solution space" refers to the entirety of possible answers to a mathematical problem. In the context of this assignment, it includes all the routes that the algorithm can generate. These routes are encapsulated in what we term as "chromosomes". Chromosomes essentially represent ordered lists of routes, signifying the sequence in which cities are visited. They serve as the potential solutions to identify the optimal route.
3. The start of the process involved a function that randomly put together a list of cities, including their x and y coordinates. After this, the program asked the user how many routes they wanted. This number was used to trigger a function that set up the starting group, which then considered both the specified size and the list of cities. Once in motion, this function orchestrated the development of multiple chromosomes and each of these held a unique arrangement of city coordinates. Finally, the function provided the specified quantity of chromosomes, aligning with the chosen population size. This pivotal step laid the foundation for the subsequent stages of the genetic algorithm.
4. Each route's fitness score is determined by going through each chromosome and calculating the total distance traveled. We found the total distance between two cities by looking at how far apart their x and y spots were, and then using a formula to calculate the exact distance. This distance was then added to a running total. After going through the whole chromosome, including one last trip from the last city back to the first, we divided one by the total distance traveled. This helped us arrange the fitness scores from the shortest route to the longest. Shorter routes are attributed higher fitness scores.
5. To determine parents for the subsequent generation of routes, the program employs two methods. The first, known as genetic elitism, involves selecting a set number of the highest-fitness routes from the existing generation to maintain a level of excellence. The second method, fitness proportionate selection, offers every route a chance for selection based on its fitness score. Routes with superior fitness scores enjoy better odds of being chosen.
6. The chosen crossover strategy for generating the next generation population was the ordered crossover method. This approach involves randomly selecting a subset of genes from the first parent to be inherited by the child. The remaining genes are then filled in from the second parent's genes, avoiding any duplication of values already chosen from the first parent. The primary objective of employing a crossover strategy is to introduce genetic diversity within the population. This diversity is essential for the evolutionary process, ultimately leading the algorithm towards finding a highly optimal solution.
7. In terms of mutation, the implemented strategy entailed a systematic traversal of the population list across generations. Each chromosome underwent a process where each gene (or index) was assigned a random probability of being swapped with another. This probability was compared against a user-defined mutation rate. If the generated number fell below the mutation rate, the function selected a random index in the chromosome for the current index to be swapped with. This mutation process was applied to every chromosome, ensuring the preservation of genetic diversity and guarding against convergence, which could hinder progress towards the optimal solution.
8. The population management strategy adopted was a modified version of the steady-state strategy. This approach involves continually introducing new generations into the population while allowing certain existing members to persist. These "elite" members, characterized by high fitness levels, are granted the privilege of enduring through successive generations. However, not all members of the population are afforded the same opportunity for persistence. Individuals with lower fitness levels are instead chosen as breeders to contribute to the development of the next generation, ultimately replacing them to make room for new members.
9. The genetic algorithm incorporated two straightforward stopping conditions. Firstly, the program concludes its run after simulating five hundred generations of chromosomes. This fixed stopping point strikes a balance, providing ample computation time for the algorithm to reach a desirable result while ensuring a quick execution. The second stopping condition hinges on detecting diminishing returns for the best answer. This is achieved by comparing the fitness levels of the best solutions between consecutive generations. If the difference between the two generations' fitness levels is exceptionally small, indicating marginal improvement, a counter variable is incremented. Once this counter reaches 200, signifying 200 generations of minimal improvement, the algorithm is terminated, and the current best solution is returned.

## References

https://www.sciencedirect.com/science/article/abs/pii/S0020025508002867#:~:text=Steady%2Dstate%20genetic%20algorithms,-The%20generational%20GA&text=A%20replacement%2Fdeletion%20strategy%20defines,slot)%20in%20the%20next%20iteration.
